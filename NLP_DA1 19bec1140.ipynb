{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_DA1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Brown Corpus"
      ],
      "metadata": {
        "id": "zyG9_MRH_UWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKcYTiEUTfZe",
        "outputId": "f5cc53ec-2835-4bc0-9f92-78459e5f0665"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categories"
      ],
      "metadata": {
        "id": "vQPNc8aV9Ucm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "brown.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdydFqORQplk",
        "outputId": "ef00108b-661e-48c5-dfb3-b024eda61b2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokens"
      ],
      "metadata": {
        "id": "-nciJqAJ9ny3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('brown.csv')\n",
        "for i in range(len('tokenized_text')):\n",
        "  words = nltk.word_tokenize(data['tokenized_text'][i])\n",
        "  print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66mp1nEvTYT_",
        "outputId": "cd1db860-86db-427c-aaf3-322303e57a81"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Furthermore', ',', 'as', 'an', 'encouragement', 'to', 'revisionist', 'thinking', ',', 'it', 'manifestly', 'is', 'fair', 'to', 'admit', 'that', 'any', 'fraternity', 'has', 'a', 'constitutional', 'right', 'to', 'refuse', 'to', 'accept', 'persons', 'it', 'dislikes', '.']\n",
            "['The', 'Unitarian', 'clergy', 'were', 'an', 'exclusive', 'club', 'of', 'cultivated', 'gentlemen', '--', 'as', 'the', 'term', 'was', 'then', 'understood', 'in', 'the', 'Back', 'Bay', '--', 'and', 'Parker', 'was', 'definitely', 'not', 'a', 'gentleman', ',', 'either', 'in', 'theology', 'or', 'in', 'manners', '.']\n",
            "['Ezra', 'Stiles', 'Gannett', ',', 'an', 'honorable', 'representative', 'of', 'the', 'sanhedrin', ',', 'addressed', 'himself', 'frankly', 'to', 'the', 'issue', 'in', '1845', ',', 'insisting', 'that', 'Parker', 'should', 'not', 'be', 'persecuted', 'or', 'calumniated', 'and', 'that', 'in', 'this', 'republic', 'no', 'power', 'to', 'restrain', 'him', 'by', 'force', 'could', 'exist', '.']\n",
            "['Even', 'so', ',', 'Gannett', 'judiciously', 'argued', ',', 'the', 'Association', 'could', 'legitimately', 'decide', 'that', 'Parker', '``', 'should', 'not', 'be', 'encouraged', 'nor', 'assisted', 'in', 'diffusing', 'his', 'opinions', 'by', 'those', 'who', 'differ', 'from', 'him', 'in', 'regard', 'to', 'their', 'correctness', '``', '.']\n",
            "['We', 'today', 'are', 'not', 'entitled', 'to', 'excoriate', 'honest', 'men', 'who', 'believed', 'Parker', 'to', 'be', 'downright', 'pernicious', 'and', 'who', 'barred', 'their', 'pulpits', 'against', 'his', 'demand', 'to', 'poison', 'the', 'minds', 'of', 'their', 'congregations', '.']\n",
            "['One', 'can', 'even', 'argue', '--', 'though', 'this', 'is', 'a', 'delicate', 'matter', '--', 'that', 'every', 'justification', 'existed', 'for', 'their', 'returning', 'the', 'Public', 'Lecture', 'to', 'the', 'First', 'Church', ',', 'and', 'so', 'to', 'suppress', 'it', ',', 'rather', 'than', 'let', 'Parker', 'use', 'it', 'as', 'a', 'sounding', 'board', 'for', 'his', 'propaganda', 'when', 'his', 'turn', 'should', 'come', 'to', 'occupy', 'it', '.']\n",
            "['Finally', ',', 'it', 'did', 'seem', 'clear', 'as', 'day', 'to', 'these', 'clergymen', ',', 'as', 'Gannett', \"'s\", 'son', 'explained', 'in', 'the', 'biography', 'of', 'his', 'father', ',', 'they', 'had', 'always', 'contended', 'for', 'the', 'propriety', 'of', 'their', 'claim', 'to', 'the', 'title', 'of', 'Christians', '.']\n",
            "['Their', 'demand', 'against', 'the', 'Calvinist', 'Orthodoxy', 'for', 'intellectual', 'liberty', 'had', 'never', 'meant', 'that', 'they', 'would', 'follow', '``', 'free', 'inquiry', '``', 'to', 'the', 'extreme', 'of', 'proclaiming', 'Christianity', 'a', '``', 'natural', '``', 'religion', '.']\n",
            "['Grant', 'all', 'this', '--', 'still', ',', 'when', 'modern', 'Unitarianism', 'and', 'the', 'Harvard', 'Divinity', 'School', 'recall', 'with', 'humorous', 'affection', 'the', 'insults', 'Parker', 'lavished', 'upon', 'them', ',', 'or', 'else', 'argue', 'that', 'after', 'all', 'Parker', 'received', 'the', 'treatment', 'he', 'invited', ',', 'they', 'betray', 'an', 'uneasy', 'conscience', '.']\n",
            "['Whenever', 'New', 'England', 'liberalism', 'is', 'reminded', 'of', 'the', 'dramatic', 'confrontation', 'of', 'Parker', 'and', 'the', 'fraternity', 'on', 'January', '23', ',', '1843', '--', 'while', 'it', 'may', 'defend', 'the', 'privilege', 'of', 'Chandler', 'Robbins', 'to', 'demand', 'that', 'Parker', 'leave', 'the', 'Association', ',', 'while', 'it', 'may', 'plead', 'that', 'Dr.', 'N.', 'L.', 'Frothingham', 'had', 'every', 'warrant', 'for', 'stating', ',', '``', 'The', 'difference', 'between', 'Trinitarians', 'and', 'Unitarians', 'is', 'a', 'difference', 'in', 'Christianity', ';', ';']\n",
            "['the', 'difference', 'between', 'Mr.', 'Parker', 'and', 'the', 'Association', 'is', 'a', 'difference', 'between', 'no', 'Christianity', 'and', 'Christianity', '``', '--', 'despite', 'these', 'supposed', 'conclusive', 'assurances', ',', 'the', 'modern', 'liberal', 'heaves', 'repeatedly', 'a', 'sigh', 'of', 'relief', ',', 'of', 'positive', 'thanksgiving', ',', 'that', 'the', 'Association', 'never', 'quite', 'brought', 'itself', 'officially', 'to', 'expel', 'Parker', '.']\n",
            "['Had', 'it', 'done', 'so', ',', 'the', 'blot', 'on', 'its', 'escutcheon', 'would', 'have', 'remained', 'indelible', ',', 'nor', 'could', 'the', 'Harvard', 'Divinity', 'School', 'assemble', 'today', 'to', 'honor', 'Parker', \"'s\", 'insurgence', 'other', 'than', 'by', 'getting', 'down', 'on', 'its', 'collective', 'knees', 'and', 'crying', '``', 'peccavi', '``', '.']\n",
            "['Happily', 'for', 'posterity', ',', 'then', ',', 'the', 'Boston', 'Association', 'did', 'not', 'actually', 'command', 'Parker', 'to', 'leave', 'the', 'room', ',', 'though', 'it', 'came', 'too', 'close', 'for', 'comfort', 'to', 'what', 'would', 'have', 'been', 'an', 'unforgivable', 'brutality', '.']\n",
            "['Fortunately', ',', 'the', 'honor', 'of', 'the', 'denomination', 'can', 'attest', 'that', 'Cyrus', 'Bartol', 'defended', 'Parker', \"'s\", 'sincerity', ',', 'as', 'did', 'also', 'Gannett', 'and', 'Chandler', 'Robbins', ';', ';']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Size"
      ],
      "metadata": {
        "id": "8P6zLwTl9uPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.count().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ectOmjb9Tpg5",
        "outputId": "c0565179-6a9a-452d-cb3e-51a8773e29e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "401380"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Size of word tokens"
      ],
      "metadata": {
        "id": "mbLg3ZRP90Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['tokenized_text'].count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQw9oz2RdhoJ",
        "outputId": "03de3bf1-d8ff-4b03-c2cc-c0fa8371646a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57340"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word types"
      ],
      "metadata": {
        "id": "HZtWahSx-dC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "pos_words = data['tokenized_text'].str.split().map(pos_tag)\n",
        "pos_words.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWn4P7dAm0GY",
        "outputId": "e7159ce5-0e21-4065-8bf9-32bc6b9d41fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [(Furthermore, RB), (,, ,), (as, IN), (an, DT)...\n",
              "1    [(The, DT), (Unitarian, JJ), (clergy, NN), (we...\n",
              "2    [(Ezra, NNP), (Stiles, NNP), (Gannett, NNP), (...\n",
              "3    [(Even, RB), (so, RB), (,, ,), (Gannett, NNP),...\n",
              "4    [(We, PRP), (today, NN), (are, VBP), (not, RB)...\n",
              "Name: tokenized_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Size of category 'government'"
      ],
      "metadata": {
        "id": "pk4pRr40-iAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_of_cat_gov = 0\n",
        "for i in range(len(data['label'])):\n",
        "  if data['label'][i] == 'government':\n",
        "    size_of_cat_gov += 1\n",
        "print(size_of_cat_gov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsraWyAhrgSk",
        "outputId": "296c41ff-fdf5-44ee-95b9-59cf787f2149"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency of tokens"
      ],
      "metadata": {
        "id": "KmMwlITN-pOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = {}\n",
        "for i in range(len('tokenized_text')):\n",
        "  words = nltk.word_tokenize(data['tokenized_text'][i])\n",
        "# iterating over the list\n",
        "  for item in words:\n",
        "    # checking the element in dictionary\n",
        "    if item in frequency:\n",
        "        # incrementing the counr\n",
        "        frequency[item] += 1\n",
        "    else:\n",
        "        # initializing the count\n",
        "        frequency[item] = 1\n",
        "\n",
        "# printing the frequency\n",
        "print(frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TuPfHuInxEX",
        "outputId": "537dc5ca-0866-4e77-f2cc-ca191bb9da0a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Furthermore': 1, ',': 29, 'as': 6, 'an': 5, 'encouragement': 1, 'to': 21, 'revisionist': 1, 'thinking': 1, 'it': 10, 'manifestly': 1, 'is': 5, 'fair': 1, 'admit': 1, 'that': 11, 'any': 1, 'fraternity': 2, 'has': 1, 'a': 8, 'constitutional': 1, 'right': 1, 'refuse': 1, 'accept': 1, 'persons': 1, 'dislikes': 1, '.': 12, 'The': 2, 'Unitarian': 1, 'clergy': 1, 'were': 1, 'exclusive': 1, 'club': 1, 'of': 13, 'cultivated': 1, 'gentlemen': 1, '--': 7, 'the': 30, 'term': 1, 'was': 2, 'then': 2, 'understood': 1, 'in': 9, 'Back': 1, 'Bay': 1, 'and': 11, 'Parker': 14, 'definitely': 1, 'not': 5, 'gentleman': 1, 'either': 1, 'theology': 1, 'or': 3, 'manners': 1, 'Ezra': 1, 'Stiles': 1, 'Gannett': 4, 'honorable': 1, 'representative': 1, 'sanhedrin': 1, 'addressed': 1, 'himself': 1, 'frankly': 1, 'issue': 1, '1845': 1, 'insisting': 1, 'should': 3, 'be': 3, 'persecuted': 1, 'calumniated': 1, 'this': 3, 'republic': 1, 'no': 2, 'power': 1, 'restrain': 1, 'him': 2, 'by': 3, 'force': 1, 'could': 3, 'exist': 1, 'Even': 1, 'so': 3, 'judiciously': 1, 'argued': 1, 'Association': 5, 'legitimately': 1, 'decide': 1, '``': 10, 'encouraged': 1, 'nor': 2, 'assisted': 1, 'diffusing': 1, 'his': 5, 'opinions': 1, 'those': 1, 'who': 3, 'differ': 1, 'from': 1, 'regard': 1, 'their': 5, 'correctness': 1, 'We': 1, 'today': 2, 'are': 1, 'entitled': 1, 'excoriate': 1, 'honest': 1, 'men': 1, 'believed': 1, 'downright': 1, 'pernicious': 1, 'barred': 1, 'pulpits': 1, 'against': 2, 'demand': 3, 'poison': 1, 'minds': 1, 'congregations': 1, 'One': 1, 'can': 2, 'even': 1, 'argue': 2, 'though': 2, 'delicate': 1, 'matter': 1, 'every': 2, 'justification': 1, 'existed': 1, 'for': 7, 'returning': 1, 'Public': 1, 'Lecture': 1, 'First': 1, 'Church': 1, 'suppress': 1, 'rather': 1, 'than': 2, 'let': 1, 'use': 1, 'sounding': 1, 'board': 1, 'propaganda': 1, 'when': 2, 'turn': 1, 'come': 1, 'occupy': 1, 'Finally': 1, 'did': 3, 'seem': 1, 'clear': 1, 'day': 1, 'these': 2, 'clergymen': 1, \"'s\": 3, 'son': 1, 'explained': 1, 'biography': 1, 'father': 1, 'they': 3, 'had': 3, 'always': 1, 'contended': 1, 'propriety': 1, 'claim': 1, 'title': 1, 'Christians': 1, 'Their': 1, 'Calvinist': 1, 'Orthodoxy': 1, 'intellectual': 1, 'liberty': 1, 'never': 2, 'meant': 1, 'would': 3, 'follow': 1, 'free': 1, 'inquiry': 1, 'extreme': 1, 'proclaiming': 1, 'Christianity': 4, 'natural': 1, 'religion': 1, 'Grant': 1, 'all': 2, 'still': 1, 'modern': 2, 'Unitarianism': 1, 'Harvard': 2, 'Divinity': 2, 'School': 2, 'recall': 1, 'with': 1, 'humorous': 1, 'affection': 1, 'insults': 1, 'lavished': 1, 'upon': 1, 'them': 1, 'else': 1, 'after': 1, 'received': 1, 'treatment': 1, 'he': 1, 'invited': 1, 'betray': 1, 'uneasy': 1, 'conscience': 1, 'Whenever': 1, 'New': 1, 'England': 1, 'liberalism': 1, 'reminded': 1, 'dramatic': 1, 'confrontation': 1, 'on': 3, 'January': 1, '23': 1, '1843': 1, 'while': 2, 'may': 2, 'defend': 1, 'privilege': 1, 'Chandler': 2, 'Robbins': 2, 'leave': 2, 'plead': 1, 'Dr.': 1, 'N.': 1, 'L.': 1, 'Frothingham': 1, 'warrant': 1, 'stating': 1, 'difference': 4, 'between': 3, 'Trinitarians': 1, 'Unitarians': 1, ';': 4, 'Mr.': 1, 'despite': 1, 'supposed': 1, 'conclusive': 1, 'assurances': 1, 'liberal': 1, 'heaves': 1, 'repeatedly': 1, 'sigh': 1, 'relief': 1, 'positive': 1, 'thanksgiving': 1, 'quite': 1, 'brought': 1, 'itself': 1, 'officially': 1, 'expel': 1, 'Had': 1, 'done': 1, 'blot': 1, 'its': 2, 'escutcheon': 1, 'have': 2, 'remained': 1, 'indelible': 1, 'assemble': 1, 'honor': 2, 'insurgence': 1, 'other': 1, 'getting': 1, 'down': 1, 'collective': 1, 'knees': 1, 'crying': 1, 'peccavi': 1, 'Happily': 1, 'posterity': 1, 'Boston': 1, 'actually': 1, 'command': 1, 'room': 1, 'came': 1, 'too': 1, 'close': 1, 'comfort': 1, 'what': 1, 'been': 1, 'unforgivable': 1, 'brutality': 1, 'Fortunately': 1, 'denomination': 1, 'attest': 1, 'Cyrus': 1, 'Bartol': 1, 'defended': 1, 'sincerity': 1, 'also': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most frequent token"
      ],
      "metadata": {
        "id": "H1o_VFcQ-yZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(frequency))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjvz69QktSNz",
        "outputId": "9ac8617b-589a-43a2-fe09-a4459d3343b8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "would\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of sentences"
      ],
      "metadata": {
        "id": "EuaSZjKF-2oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['tokenized_text'].count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czWhAcwSzFbL",
        "outputId": "5b1bef28-c401-4643-f84b-fbb6ca461463"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57340"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring other NLTK Corpora"
      ],
      "metadata": {
        "id": "68DoLn8H_E1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plaintext corpora"
      ],
      "metadata": {
        "id": "b70DaWgjAhcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('abc')\n",
        " nltk.download('genesis')\n",
        " nltk.download('gutenberg')\n",
        " nltk.download('inaugural')\n",
        " nltk.download('state_union')\n",
        " nltk.download('webtext')\n",
        "\n",
        "print(nltk.corpus.abc.words())\n",
        "print(nltk.corpus.genesis.words())\n",
        "print(nltk.corpus.gutenberg.words(fileids='austen-emma.txt'))\n",
        "print(nltk.corpus.inaugural.words())\n",
        "print(nltk.corpus.state_union.words())\n",
        "print(nltk.corpus.webtext.words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3sWEGrJA5m3",
        "outputId": "1922686c-e144-41c0-ba51-3cc97a454458"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PM', 'denies', 'knowledge', 'of', 'AWB', 'kickbacks', ...]\n",
            "['In', 'the', 'beginning', 'God', 'created', 'the', ...]\n",
            "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]\n",
            "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]\n",
            "['PRESIDENT', 'HARRY', 'S', '.', 'TRUMAN', \"'\", 'S', ...]\n",
            "['Cookie', 'Manager', ':', '\"', 'Don', \"'\", 't', ...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Package abc is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Package state_union is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tagged corpora"
      ],
      "metadata": {
        "id": "EWDmtnfyCpGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "print(brown.words())\n",
        "print(brown.tagged_words())\n",
        "print(brown.sents())\n",
        "print(brown.tagged_sents())\n",
        "print(brown.paras(categories='reviews'))\n",
        "print(brown.tagged_paras(categories='reviews'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3fOL9oCvXI",
        "outputId": "f1102520-56d6-4b56-afad-5cd9d95ed62f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n",
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
            "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n",
            "[[['It', 'is', 'not', 'news', 'that', 'Nathan', 'Milstein', 'is', 'a', 'wizard', 'of', 'the', 'violin', '.'], ['Certainly', 'not', 'in', 'Orchestra', 'Hall', 'where', 'he', 'has', 'played', 'countless', 'recitals', ',', 'and', 'where', 'Thursday', 'night', 'he', 'celebrated', 'his', '20th', 'season', 'with', 'the', 'Chicago', 'Symphony', 'Orchestra', ',', 'playing', 'the', 'Brahms', 'Concerto', 'with', 'his', 'own', 'slashing', ',', 'demon-ridden', 'cadenza', 'melting', 'into', 'the', 'high', ',', 'pale', ',', 'pure', 'and', 'lovely', 'song', 'with', 'which', 'a', 'violinist', 'unlocks', 'the', 'heart', 'of', 'the', 'music', ',', 'or', 'forever', 'finds', 'it', 'closed', '.']], [['There', 'was', 'about', 'that', 'song', 'something', 'incandescent', ',', 'for', 'this', 'Brahms', 'was', 'Milstein', 'at', 'white', 'heat', '.'], ['Not', 'the', 'noblest', 'performance', 'we', 'have', 'heard', 'him', 'play', ',', 'or', 'the', 'most', 'spacious', ',', 'or', 'even', 'the', 'most', 'eloquent', '.'], ['Those', 'would', 'be', 'reserved', 'for', 'the', \"orchestra's\", 'great', 'nights', 'when', 'the', 'soloist', 'can', 'surpass', 'himself', '.'], ['This', 'time', 'the', 'orchestra', 'gave', 'him', 'some', 'superb', 'support', 'fired', 'by', 'response', 'to', 'his', 'own', 'high', 'mood', '.'], ['But', 'he', 'had', 'in', 'Walter', 'Hendl', 'a', 'willing', 'conductor', 'able', 'only', 'up', 'to', 'a', 'point', '.']], ...]\n",
            "[[[('It', 'PPS'), ('is', 'BEZ'), ('not', '*'), ('news', 'NN'), ('that', 'CS'), ('Nathan', 'NP'), ('Milstein', 'NP'), ('is', 'BEZ'), ('a', 'AT'), ('wizard', 'NN'), ('of', 'IN'), ('the', 'AT'), ('violin', 'NN'), ('.', '.')], [('Certainly', 'RB'), ('not', '*'), ('in', 'IN'), ('Orchestra', 'NN-TL'), ('Hall', 'NN-TL'), ('where', 'WRB'), ('he', 'PPS'), ('has', 'HVZ'), ('played', 'VBN'), ('countless', 'JJ'), ('recitals', 'NNS'), (',', ','), ('and', 'CC'), ('where', 'WRB'), ('Thursday', 'NR'), ('night', 'NN'), ('he', 'PPS'), ('celebrated', 'VBD'), ('his', 'PP$'), ('20th', 'OD'), ('season', 'NN'), ('with', 'IN'), ('the', 'AT'), ('Chicago', 'NP-TL'), ('Symphony', 'NN-TL'), ('Orchestra', 'NN-TL'), (',', ','), ('playing', 'VBG'), ('the', 'AT'), ('Brahms', 'NP-TL'), ('Concerto', 'NN-TL'), ('with', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('slashing', 'VBG'), (',', ','), ('demon-ridden', 'JJ'), ('cadenza', 'NN'), ('melting', 'VBG'), ('into', 'IN'), ('the', 'AT'), ('high', 'JJ'), (',', ','), ('pale', 'JJ'), (',', ','), ('pure', 'JJ'), ('and', 'CC'), ('lovely', 'JJ'), ('song', 'NN'), ('with', 'IN'), ('which', 'WDT'), ('a', 'AT'), ('violinist', 'NN'), ('unlocks', 'VBZ'), ('the', 'AT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'AT'), ('music', 'NN'), (',', ','), ('or', 'CC'), ('forever', 'RB'), ('finds', 'VBZ'), ('it', 'PPO'), ('closed', 'VBN'), ('.', '.')]], [[('There', 'EX'), ('was', 'BEDZ'), ('about', 'IN'), ('that', 'DT'), ('song', 'NN'), ('something', 'PN'), ('incandescent', 'JJ'), (',', ','), ('for', 'CS'), ('this', 'DT'), ('Brahms', 'NP'), ('was', 'BEDZ'), ('Milstein', 'NP'), ('at', 'IN'), ('white', 'JJ'), ('heat', 'NN'), ('.', '.')], [('Not', '*'), ('the', 'AT'), ('noblest', 'JJT'), ('performance', 'NN'), ('we', 'PPSS'), ('have', 'HV'), ('heard', 'VBN'), ('him', 'PPO'), ('play', 'VB'), (',', ','), ('or', 'CC'), ('the', 'AT'), ('most', 'QL'), ('spacious', 'JJ'), (',', ','), ('or', 'CC'), ('even', 'RB'), ('the', 'AT'), ('most', 'QL'), ('eloquent', 'JJ'), ('.', '.')], [('Those', 'DTS'), ('would', 'MD'), ('be', 'BE'), ('reserved', 'VBN'), ('for', 'IN'), ('the', 'AT'), (\"orchestra's\", 'NN$'), ('great', 'JJ'), ('nights', 'NNS'), ('when', 'WRB'), ('the', 'AT'), ('soloist', 'NN'), ('can', 'MD'), ('surpass', 'VB'), ('himself', 'PPL'), ('.', '.')], [('This', 'DT'), ('time', 'NN'), ('the', 'AT'), ('orchestra', 'NN'), ('gave', 'VBD'), ('him', 'PPO'), ('some', 'DTI'), ('superb', 'JJ'), ('support', 'NN'), ('fired', 'VBN'), ('by', 'IN'), ('response', 'NN'), ('to', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('high', 'JJ'), ('mood', 'NN'), ('.', '.')], [('But', 'CC'), ('he', 'PPS'), ('had', 'HVD'), ('in', 'IN'), ('Walter', 'NP'), ('Hendl', 'NP'), ('a', 'AT'), ('willing', 'JJ'), ('conductor', 'NN'), ('able', 'JJ'), ('only', 'RB'), ('up', 'IN'), ('to', 'IN'), ('a', 'AT'), ('point', 'NN'), ('.', '.')]], ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunked corpora"
      ],
      "metadata": {
        "id": "txgqAZBWDRKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('conll2000')\n",
        " nltk.download('conll2002')\n",
        "\n",
        "from nltk.corpus import conll2000, conll2002\n",
        "print(conll2000.sents())\n",
        "for tree in conll2000.chunked_sents()[:2]:\n",
        "  print(tree)\n",
        "print(conll2002.sents())\n",
        "for tree in conll2002.chunked_sents()[:2]:\n",
        "  print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8KH9YUrDYik",
        "outputId": "e1b663ef-082e-46d4-cb6c-bb19b824aec9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'September', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'July', 'and', 'August', \"'s\", 'near-record', 'deficits', '.'], ['Chancellor', 'of', 'the', 'Exchequer', 'Nigel', 'Lawson', \"'s\", 'restated', 'commitment', 'to', 'a', 'firm', 'monetary', 'policy', 'has', 'helped', 'to', 'prevent', 'a', 'freefall', 'in', 'sterling', 'over', 'the', 'past', 'week', '.'], ...]\n",
            "(S\n",
            "  (NP Confidence/NN)\n",
            "  (PP in/IN)\n",
            "  (NP the/DT pound/NN)\n",
            "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
            "  (NP another/DT sharp/JJ dive/NN)\n",
            "  if/IN\n",
            "  (NP trade/NN figures/NNS)\n",
            "  (PP for/IN)\n",
            "  (NP September/NNP)\n",
            "  ,/,\n",
            "  due/JJ\n",
            "  (PP for/IN)\n",
            "  (NP release/NN)\n",
            "  (NP tomorrow/NN)\n",
            "  ,/,\n",
            "  (VP fail/VB to/TO show/VB)\n",
            "  (NP a/DT substantial/JJ improvement/NN)\n",
            "  (PP from/IN)\n",
            "  (NP July/NNP and/CC August/NNP)\n",
            "  (NP 's/POS near-record/JJ deficits/NNS)\n",
            "  ./.)\n",
            "(S\n",
            "  Chancellor/NNP\n",
            "  (PP of/IN)\n",
            "  (NP the/DT Exchequer/NNP)\n",
            "  (NP Nigel/NNP Lawson/NNP)\n",
            "  (NP 's/POS restated/VBN commitment/NN)\n",
            "  (PP to/TO)\n",
            "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
            "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
            "  (NP a/DT freefall/NN)\n",
            "  (PP in/IN)\n",
            "  (NP sterling/NN)\n",
            "  (PP over/IN)\n",
            "  (NP the/DT past/JJ week/NN)\n",
            "  ./.)\n",
            "[['Sao', 'Paulo', '(', 'Brasil', ')', ',', '23', 'may', '(', 'EFECOM', ')', '.'], ['-'], ...]\n",
            "(S\n",
            "  (LOC Sao/NC Paulo/VMI)\n",
            "  (/Fpa\n",
            "  (LOC Brasil/NC)\n",
            "  )/Fpt\n",
            "  ,/Fc\n",
            "  23/Z\n",
            "  may/NC\n",
            "  (/Fpa\n",
            "  (ORG EFECOM/NP)\n",
            "  )/Fpt\n",
            "  ./Fp)\n",
            "(S -/Fg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2002 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}